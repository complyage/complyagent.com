version: "3.9"

services:

# ==============================================================================
# Agent :: OCR
# ------------------------------------------------------------------------------
# Performs optical character recognition on images (PaddleOCR)
# GPU acceleration is enabled for massive throughput improvements.
# ==============================================================================

  agent_ocr:
    build:
      context: ./agents/ocr
      dockerfile: Dockerfile
    container_name: agent_ocr
    ports:
      - "50051:8080"
    volumes:
      - ./agents/ocr:/app
    working_dir: /app
    networks:
      - complyagent_internal
      - default  # Allow internet access
    environment:
      - NVIDIA_VISIBLE_DEVICES=all         # Enable GPU access
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]          # Reserve GPU for this container
    runtime: nvidia                        # Use NVIDIA container runtime

# ==============================================================================
# Agent :: Face
# ------------------------------------------------------------------------------
# Handles face detection, age, and gender prediction using ONNX / InsightFace.
# GPU acceleration significantly speeds up inference time.
# ==============================================================================

  agent_face:
    build:
      context: ./agents/face
      dockerfile: Dockerfile
    container_name: agent_face
    ports:
      - "50052:8080"
    volumes:
      - ./agents/face:/app
    working_dir: /app
    networks:
      - complyagent_internal
      - default  # Allow internet access
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    runtime: nvidia

# ==============================================================================
# Agent :: NSFW
# ------------------------------------------------------------------------------
# Classifies explicit or inappropriate content using transformer-based models.
# GPU acceleration improves batch processing performance dramatically.
# ==============================================================================

  agent_nsfw:
    build:
      context: ./agents/nsfw
      dockerfile: Dockerfile
    container_name: agent_nsfw
    ports:
      - "50054:8080"
    volumes:
      - ./agents/nsfw:/app
    working_dir: /app
    networks:
      - complyagent_internal
      - default
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    runtime: nvidia

# ==============================================================================
# Agent :: Ollama
# ------------------------------------------------------------------------------
# Hosts the Ollama LLM server (Phi-3, LLaMA, etc.).
# Required for generating SEO-friendly descriptions and text responses.
# ==============================================================================

  agent_ollama:
    build:
      context: ./agents/ollama
      dockerfile: Dockerfile
    container_name: agent_ollama
    ports:
      - "50053:11434"
    volumes:
      - ollama_models:/root/.ollama         # Persist model cache
    environment:
      - NVIDIA_VISIBLE_DEVICES=all          # Allow full GPU visibility
      - OLLAMA_USE_GPU=true                 # Force Ollama to use GPU
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]           # Reserve GPU for LLM inference
    runtime: nvidia

# ==============================================================================
# Agent :: Caption
# ------------------------------------------------------------------------------
# Generates short descriptive captions (possibly using Ollama internally).
# GPU support allows faster text or vision model inference.
# ==============================================================================

  agent_caption:
    build:
      context: ./agents/caption
      dockerfile: Dockerfile
    container_name: agent_caption
    ports:
      - "50055:8080"
    volumes:
      - ./agents/caption:/app
    working_dir: /app
    networks:
      - complyagent_internal
      - default
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    runtime: nvidia

# ==============================================================================
# Networks
# ------------------------------------------------------------------------------
# Internal network: Used for private inter-agent communication (no internet)
# Default network: Provides outbound access for model downloads or API calls.
# ==============================================================================

networks:
  complyagent_internal:
    driver: bridge
    internal: true  # No internet access
  default:
    driver: bridge  # Internet access

# ==============================================================================
# Volumes
# ------------------------------------------------------------------------------
# Persistent model cache for Ollama â€” ensures models are not re-downloaded.
# ==============================================================================

volumes:
  ollama_models:
